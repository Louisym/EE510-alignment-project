"""
Training Callbacks with Visualization
é›†æˆå¯è§†åŒ–åŠŸèƒ½çš„è®­ç»ƒå›è°ƒ
"""

import os
from pathlib import Path
from typing import Dict, Optional
from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl
import torch

from training.visualization import MetricsTracker


class VisualizationCallback(TrainerCallback):
    """
    HuggingFace Trainer çš„å¯è§†åŒ–å›è°ƒ
    ç”¨äº SFT è®­ç»ƒçš„æŒ‡æ ‡è¿½è¸ªå’Œå¯è§†åŒ–
    """

    def __init__(self, output_dir: str, experiment_name: str = "sft_training"):
        """
        åˆå§‹åŒ–å›è°ƒ

        Args:
            output_dir: è¾“å‡ºç›®å½•
            experiment_name: å®éªŒåç§°
        """
        self.tracker = MetricsTracker(output_dir, experiment_name)
        self.experiment_name = experiment_name

    def on_log(self, args: TrainingArguments, state: TrainerState,
               control: TrainerControl, logs: Dict[str, float] = None, **kwargs):
        """
        æ¯æ¬¡è®°å½•æ—¥å¿—æ—¶è°ƒç”¨

        Args:
            args: è®­ç»ƒå‚æ•°
            state: è®­ç»ƒçŠ¶æ€
            control: è®­ç»ƒæ§åˆ¶
            logs: æ—¥å¿—å­—å…¸
        """
        if logs is None:
            return

        # æå–æŒ‡æ ‡
        metrics = {}

        if 'loss' in logs:
            metrics['train_loss'] = logs['loss']

        if 'eval_loss' in logs:
            metrics['val_loss'] = logs['eval_loss']

        if 'learning_rate' in logs:
            metrics['learning_rate'] = logs['learning_rate']

        # è®°å½•æŒ‡æ ‡
        if metrics:
            epoch = state.epoch if state.epoch is not None else 0
            self.tracker.log_metrics(
                step=state.global_step,
                epoch=int(epoch),
                metrics=metrics
            )

    def on_epoch_end(self, args: TrainingArguments, state: TrainerState,
                    control: TrainerControl, **kwargs):
        """
        æ¯ä¸ª epoch ç»“æŸæ—¶è°ƒç”¨
        """
        # ä¿å­˜æŒ‡æ ‡
        self.tracker.save_metrics()

    def on_train_end(self, args: TrainingArguments, state: TrainerState,
                    control: TrainerControl, **kwargs):
        """
        è®­ç»ƒç»“æŸæ—¶è°ƒç”¨
        """
        print("\n" + "="*70)
        print("ğŸ“Š Generating training visualizations...")
        print("="*70)

        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
        self.tracker.save_metrics()

        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        self.tracker.plot_all()

        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        self.tracker.generate_summary_report()

        # åˆ›å»ºä»ªè¡¨æ¿
        from training.visualization import create_training_dashboard
        create_training_dashboard(self.tracker)

        print("\nâœ“ Visualization complete! Check the plots directory for results.")


class GRPOVisualizationCallback:
    """
    GRPO Trainer çš„å¯è§†åŒ–å›è°ƒ
    å› ä¸º GRPO ä¸ä½¿ç”¨ HuggingFace Trainerï¼Œéœ€è¦æ‰‹åŠ¨é›†æˆ
    """

    def __init__(self, output_dir: str, experiment_name: str = "grpo_training"):
        """
        åˆå§‹åŒ–å›è°ƒ

        Args:
            output_dir: è¾“å‡ºç›®å½•
            experiment_name: å®éªŒåç§°
        """
        self.tracker = MetricsTracker(output_dir, experiment_name)
        self.experiment_name = experiment_name

    def log_metrics(self, step: int, epoch: int, metrics: Dict[str, float]):
        """
        è®°å½•è®­ç»ƒæŒ‡æ ‡

        Args:
            step: æ­¥æ•°
            epoch: epoch æ•°
            metrics: æŒ‡æ ‡å­—å…¸
        """
        # è®°å½•åˆ° tracker
        self.tracker.log_metrics(step, epoch, metrics)

        # åŒæ—¶è®°å½• GRPO ä¸“ç”¨æŒ‡æ ‡
        if any(key in metrics for key in ['mean_reward', 'max_reward', 'min_reward', 'kl_divergence']):
            self.tracker.log_grpo_metrics(step, metrics)

    def on_epoch_end(self, epoch: int):
        """Epoch ç»“æŸæ—¶è°ƒç”¨"""
        self.tracker.save_metrics()

        # ç”Ÿæˆä¸­é—´å›¾è¡¨
        if epoch % 2 == 0:  # æ¯ 2 ä¸ª epoch ç”Ÿæˆä¸€æ¬¡å›¾è¡¨
            self.tracker.plot_all()

    def on_train_end(self):
        """è®­ç»ƒç»“æŸæ—¶è°ƒç”¨"""
        print("\n" + "="*70)
        print("ğŸ“Š Generating GRPO training visualizations...")
        print("="*70)

        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
        self.tracker.save_metrics()

        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        self.tracker.plot_all()

        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        self.tracker.generate_summary_report()

        # åˆ›å»ºä»ªè¡¨æ¿
        from training.visualization import create_training_dashboard
        create_training_dashboard(self.tracker)

        print("\nâœ“ GRPO Visualization complete!")


if __name__ == "__main__":
    print("Testing Visualization Callbacks...")

    # æµ‹è¯• GRPO callback
    callback = GRPOVisualizationCallback("./test_callback_output", "test_grpo")

    # æ¨¡æ‹Ÿè®­ç»ƒ
    import numpy as np
    for epoch in range(3):
        for step in range(20):
            global_step = epoch * 20 + step
            callback.log_metrics(
                step=global_step,
                epoch=epoch,
                metrics={
                    'loss': 2.0 * np.exp(-global_step/30) + 0.1,
                    'mean_reward': 0.5 + 0.3 * global_step / 60,
                    'max_reward': 0.7 + 0.25 * global_step / 60,
                    'min_reward': 0.3 + 0.15 * global_step / 60,
                    'kl_divergence': 0.1 * np.exp(-global_step/30)
                }
            )

        callback.on_epoch_end(epoch)

    callback.on_train_end()
    print("âœ“ Test completed!")
