"""
Training Visualization and Metrics Tracking
ç”¨äº Presentation å’Œ Report çš„å®Œæ•´å¯è§†åŒ–å·¥å…·
"""

import os
import json
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import pandas as pd

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆå¯é€‰ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
sns.set_palette("husl")


class MetricsTracker:
    """è®­ç»ƒæŒ‡æ ‡è¿½è¸ªå™¨"""

    def __init__(self, output_dir: str, experiment_name: str = "training"):
        """
        åˆå§‹åŒ–æŒ‡æ ‡è¿½è¸ªå™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
            experiment_name: å®éªŒåç§°
        """
        self.output_dir = Path(output_dir)
        self.experiment_name = experiment_name
        self.metrics_dir = self.output_dir / "metrics"
        self.plots_dir = self.output_dir / "plots"

        # åˆ›å»ºç›®å½•
        self.metrics_dir.mkdir(parents=True, exist_ok=True)
        self.plots_dir.mkdir(parents=True, exist_ok=True)

        # æŒ‡æ ‡å†å²
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'learning_rate': [],
            'epoch': [],
            'step': [],
            'timestamp': []
        }

        # GRPO ä¸“ç”¨æŒ‡æ ‡
        self.grpo_history = {
            'mean_reward': [],
            'max_reward': [],
            'min_reward': [],
            'kl_divergence': [],
            'step': []
        }

        print(f"ğŸ“Š MetricsTracker initialized: {self.plots_dir}")

    def log_metrics(self, step: int, epoch: int, metrics: Dict[str, float]):
        """
        è®°å½•è®­ç»ƒæŒ‡æ ‡

        Args:
            step: è®­ç»ƒæ­¥æ•°
            epoch: å½“å‰ epoch
            metrics: æŒ‡æ ‡å­—å…¸
        """
        self.history['step'].append(step)
        self.history['epoch'].append(epoch)
        self.history['timestamp'].append(datetime.now().isoformat())

        # è®°å½•æ‰€æœ‰æŒ‡æ ‡
        for key, value in metrics.items():
            if key not in self.history:
                self.history[key] = []
            self.history[key].append(value)

    def log_grpo_metrics(self, step: int, metrics: Dict[str, float]):
        """
        è®°å½• GRPO ä¸“ç”¨æŒ‡æ ‡

        Args:
            step: è®­ç»ƒæ­¥æ•°
            metrics: GRPO æŒ‡æ ‡
        """
        self.grpo_history['step'].append(step)

        for key in ['mean_reward', 'max_reward', 'min_reward', 'kl_divergence']:
            if key in metrics:
                self.grpo_history[key].append(metrics[key])

    def save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ° JSON æ–‡ä»¶"""
        # ä¿å­˜ä¸»è¦æŒ‡æ ‡
        metrics_path = self.metrics_dir / f"{self.experiment_name}_metrics.json"
        with open(metrics_path, 'w') as f:
            json.dump(self.history, f, indent=2)

        # ä¿å­˜ GRPO æŒ‡æ ‡
        if self.grpo_history['step']:
            grpo_path = self.metrics_dir / f"{self.experiment_name}_grpo_metrics.json"
            with open(grpo_path, 'w') as f:
                json.dump(self.grpo_history, f, indent=2)

        print(f"âœ“ Metrics saved to {metrics_path}")

    def plot_loss_curves(self, save: bool = True, show: bool = False):
        """
        ç»˜åˆ¶æŸå¤±æ›²çº¿

        Args:
            save: æ˜¯å¦ä¿å­˜å›¾ç‰‡
            show: æ˜¯å¦æ˜¾ç¤ºå›¾ç‰‡
        """
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))

        # è®­ç»ƒæŸå¤± vs æ­¥æ•°
        if 'train_loss' in self.history and self.history['train_loss']:
            axes[0].plot(self.history['step'], self.history['train_loss'],
                        label='Training Loss', linewidth=2, marker='o', markersize=3)

            if 'val_loss' in self.history and self.history['val_loss']:
                # éªŒè¯æŸå¤±å¯èƒ½ä¸æ˜¯æ¯æ­¥éƒ½æœ‰
                val_steps = [s for s, v in zip(self.history['step'], self.history['val_loss']) if v is not None]
                val_losses = [v for v in self.history['val_loss'] if v is not None]
                axes[0].plot(val_steps, val_losses,
                            label='Validation Loss', linewidth=2, marker='s', markersize=3)

            axes[0].set_xlabel('Training Steps', fontsize=12)
            axes[0].set_ylabel('Loss', fontsize=12)
            axes[0].set_title('Loss Curves', fontsize=14, fontweight='bold')
            axes[0].legend(fontsize=10)
            axes[0].grid(True, alpha=0.3)

        # è®­ç»ƒæŸå¤± vs Epoch
        if 'epoch' in self.history and 'train_loss' in self.history:
            # æŒ‰ epoch åˆ†ç»„è®¡ç®—å¹³å‡æŸå¤±
            # è¿‡æ»¤æ‰ None å€¼
            valid_data = [(e, l) for e, l in zip(self.history['epoch'], self.history['train_loss'])
                         if l is not None]
            if valid_data:
                epochs, losses = zip(*valid_data)
                df = pd.DataFrame({
                    'epoch': epochs,
                    'train_loss': losses
                })
                epoch_loss = df.groupby('epoch')['train_loss'].mean()
            else:
                epoch_loss = None

            if epoch_loss is not None:
                axes[1].plot(epoch_loss.index, epoch_loss.values,
                            label='Training Loss', linewidth=2, marker='o', markersize=5)

                axes[1].set_xlabel('Epoch', fontsize=12)
                axes[1].set_ylabel('Average Loss', fontsize=12)
                axes[1].set_title('Loss per Epoch', fontsize=14, fontweight='bold')
                axes[1].legend(fontsize=10)
                axes[1].grid(True, alpha=0.3)

        plt.tight_layout()

        if save:
            save_path = self.plots_dir / f"{self.experiment_name}_loss_curves.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ Loss curves saved to {save_path}")

        if show:
            plt.show()
        else:
            plt.close()

    def plot_learning_rate(self, save: bool = True, show: bool = False):
        """
        ç»˜åˆ¶å­¦ä¹ ç‡å˜åŒ–æ›²çº¿

        Args:
            save: æ˜¯å¦ä¿å­˜
            show: æ˜¯å¦æ˜¾ç¤º
        """
        if 'learning_rate' not in self.history or not self.history['learning_rate']:
            print("âš  No learning rate data to plot")
            return

        plt.figure(figsize=(10, 5))
        plt.plot(self.history['step'], self.history['learning_rate'],
                linewidth=2, color='coral')
        plt.xlabel('Training Steps', fontsize=12)
        plt.ylabel('Learning Rate', fontsize=12)
        plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        if save:
            save_path = self.plots_dir / f"{self.experiment_name}_learning_rate.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ Learning rate plot saved to {save_path}")

        if show:
            plt.show()
        else:
            plt.close()

    def plot_grpo_rewards(self, save: bool = True, show: bool = False):
        """
        ç»˜åˆ¶ GRPO å¥–åŠ±æ›²çº¿

        Args:
            save: æ˜¯å¦ä¿å­˜
            show: æ˜¯å¦æ˜¾ç¤º
        """
        if not self.grpo_history['step']:
            print("âš  No GRPO reward data to plot")
            return

        fig, axes = plt.subplots(1, 2, figsize=(15, 5))

        # å¥–åŠ±å˜åŒ–
        axes[0].plot(self.grpo_history['step'], self.grpo_history['mean_reward'],
                    label='Mean Reward', linewidth=2, marker='o', markersize=3)
        axes[0].fill_between(
            self.grpo_history['step'],
            self.grpo_history['min_reward'],
            self.grpo_history['max_reward'],
            alpha=0.2,
            label='Min-Max Range'
        )
        axes[0].set_xlabel('Training Steps', fontsize=12)
        axes[0].set_ylabel('Reward', fontsize=12)
        axes[0].set_title('GRPO Rewards Over Training', fontsize=14, fontweight='bold')
        axes[0].legend(fontsize=10)
        axes[0].grid(True, alpha=0.3)

        # KL æ•£åº¦
        if self.grpo_history.get('kl_divergence'):
            axes[1].plot(self.grpo_history['step'], self.grpo_history['kl_divergence'],
                        linewidth=2, color='red', marker='s', markersize=3)
            axes[1].set_xlabel('Training Steps', fontsize=12)
            axes[1].set_ylabel('KL Divergence', fontsize=12)
            axes[1].set_title('KL Divergence from Reference Model', fontsize=14, fontweight='bold')
            axes[1].grid(True, alpha=0.3)

        plt.tight_layout()

        if save:
            save_path = self.plots_dir / f"{self.experiment_name}_grpo_rewards.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ GRPO rewards plot saved to {save_path}")

        if show:
            plt.show()
        else:
            plt.close()

    def plot_all(self):
        """ç”Ÿæˆæ‰€æœ‰å›¾è¡¨"""
        print("\n" + "="*60)
        print("ğŸ“Š Generating all plots...")
        print("="*60)

        self.plot_loss_curves(save=True, show=False)
        self.plot_learning_rate(save=True, show=False)

        if self.grpo_history['step']:
            self.plot_grpo_rewards(save=True, show=False)

        print(f"\nâœ“ All plots saved to: {self.plots_dir}")

    def generate_summary_report(self) -> str:
        """
        ç”Ÿæˆè®­ç»ƒæ‘˜è¦æŠ¥å‘Š

        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = []
        report_lines.append("=" * 70)
        report_lines.append(f"TRAINING SUMMARY REPORT: {self.experiment_name}")
        report_lines.append("=" * 70)
        report_lines.append("")

        # åŸºæœ¬ä¿¡æ¯
        if self.history['step']:
            report_lines.append(f"Total training steps: {self.history['step'][-1]}")
            report_lines.append(f"Total epochs: {max(self.history['epoch'])}")

        # è®­ç»ƒæŸå¤±ç»Ÿè®¡
        if self.history.get('train_loss'):
            train_losses = [l for l in self.history['train_loss'] if l is not None]
            report_lines.append(f"\nTraining Loss:")
            report_lines.append(f"  Initial: {train_losses[0]:.4f}")
            report_lines.append(f"  Final: {train_losses[-1]:.4f}")
            report_lines.append(f"  Best: {min(train_losses):.4f}")
            report_lines.append(f"  Improvement: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.2f}%")

        # éªŒè¯æŸå¤±ç»Ÿè®¡
        if self.history.get('val_loss'):
            val_losses = [l for l in self.history['val_loss'] if l is not None]
            if val_losses:
                report_lines.append(f"\nValidation Loss:")
                report_lines.append(f"  Best: {min(val_losses):.4f}")
                report_lines.append(f"  Final: {val_losses[-1]:.4f}")

        # GRPO ç»Ÿè®¡
        if self.grpo_history['step']:
            report_lines.append(f"\nGRPO Metrics:")
            report_lines.append(f"  Initial mean reward: {self.grpo_history['mean_reward'][0]:.4f}")
            report_lines.append(f"  Final mean reward: {self.grpo_history['mean_reward'][-1]:.4f}")
            report_lines.append(f"  Best mean reward: {max(self.grpo_history['mean_reward']):.4f}")
            improvement = ((self.grpo_history['mean_reward'][-1] - self.grpo_history['mean_reward'][0]) /
                          abs(self.grpo_history['mean_reward'][0]) * 100)
            report_lines.append(f"  Improvement: {improvement:.2f}%")

        report_lines.append("")
        report_lines.append("=" * 70)

        report_text = "\n".join(report_lines)

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.metrics_dir / f"{self.experiment_name}_summary.txt"
        with open(report_path, 'w') as f:
            f.write(report_text)

        print(report_text)
        print(f"\nâœ“ Summary report saved to {report_path}")

        return report_text


class ModelComparator:
    """æ¨¡å‹å¯¹æ¯”å·¥å…· - ç”¨äºæ¯”è¾ƒ Base/SFT/GRPO æ¨¡å‹"""

    def __init__(self, output_dir: str):
        """
        åˆå§‹åŒ–æ¨¡å‹å¯¹æ¯”å™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.comparison_dir = self.output_dir / "comparisons"
        self.comparison_dir.mkdir(parents=True, exist_ok=True)

        # å­˜å‚¨å„æ¨¡å‹çš„è¾“å‡º
        self.model_outputs = {
            'base': [],
            'sft': [],
            'grpo': []
        }

        self.questions = []

    def add_comparison(self, question: str, base_output: str,
                      sft_output: str = "", grpo_output: str = ""):
        """
        æ·»åŠ ä¸€ä¸ªå¯¹æ¯”æ ·æœ¬

        Args:
            question: é—®é¢˜
            base_output: åŸºç¡€æ¨¡å‹è¾“å‡º
            sft_output: SFT æ¨¡å‹è¾“å‡º
            grpo_output: GRPO æ¨¡å‹è¾“å‡º
        """
        self.questions.append(question)
        self.model_outputs['base'].append(base_output)
        self.model_outputs['sft'].append(sft_output)
        self.model_outputs['grpo'].append(grpo_output)

    def save_comparison_table(self):
        """ä¿å­˜å¯¹æ¯”è¡¨æ ¼"""
        comparison_data = []

        for i, question in enumerate(self.questions):
            comparison_data.append({
                'Question': question[:100] + "..." if len(question) > 100 else question,
                'Base Model': self.model_outputs['base'][i][:200] + "..." if len(self.model_outputs['base'][i]) > 200 else self.model_outputs['base'][i],
                'SFT Model': self.model_outputs['sft'][i][:200] + "..." if i < len(self.model_outputs['sft']) and self.model_outputs['sft'][i] else "N/A",
                'GRPO Model': self.model_outputs['grpo'][i][:200] + "..." if i < len(self.model_outputs['grpo']) and self.model_outputs['grpo'][i] else "N/A"
            })

        df = pd.DataFrame(comparison_data)

        # ä¿å­˜ä¸º CSV
        csv_path = self.comparison_dir / "model_comparison.csv"
        df.to_csv(csv_path, index=False)
        print(f"âœ“ Comparison table saved to {csv_path}")

        # ä¿å­˜ä¸º markdownï¼ˆé€‚åˆ reportï¼‰
        md_path = self.comparison_dir / "model_comparison.md"
        with open(md_path, 'w') as f:
            f.write("# Model Output Comparison\n\n")
            f.write(df.to_markdown(index=False))

        print(f"âœ“ Comparison markdown saved to {md_path}")

    def plot_comparison_metrics(self, metrics: Dict[str, Dict[str, float]],
                               save: bool = True, show: bool = False):
        """
        ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”æŒ‡æ ‡

        Args:
            metrics: å„æ¨¡å‹çš„æŒ‡æ ‡ï¼Œæ ¼å¼: {'base': {'loss': x, ...}, 'sft': {...}, 'grpo': {...}}
            save: æ˜¯å¦ä¿å­˜
            show: æ˜¯å¦æ˜¾ç¤º
        """
        models = list(metrics.keys())
        metric_names = list(metrics[models[0]].keys())

        fig, axes = plt.subplots(1, len(metric_names), figsize=(6*len(metric_names), 5))

        if len(metric_names) == 1:
            axes = [axes]

        for idx, metric_name in enumerate(metric_names):
            values = [metrics[model].get(metric_name, 0) for model in models]
            colors = ['#3498db', '#2ecc71', '#e74c3c'][:len(models)]

            axes[idx].bar(models, values, color=colors, alpha=0.7, edgecolor='black')
            axes[idx].set_ylabel(metric_name, fontsize=12)
            axes[idx].set_title(f'{metric_name} Comparison', fontsize=14, fontweight='bold')
            axes[idx].grid(True, alpha=0.3, axis='y')

            # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
            for i, (model, value) in enumerate(zip(models, values)):
                axes[idx].text(i, value, f'{value:.4f}',
                             ha='center', va='bottom', fontsize=10)

        plt.tight_layout()

        if save:
            save_path = self.comparison_dir / "metrics_comparison.png"
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ Metrics comparison plot saved to {save_path}")

        if show:
            plt.show()
        else:
            plt.close()


def create_training_dashboard(metrics_tracker: MetricsTracker,
                              output_path: Optional[str] = None):
    """
    åˆ›å»ºè®­ç»ƒä»ªè¡¨æ¿ï¼ˆæ‰€æœ‰å›¾è¡¨åœ¨ä¸€ä¸ªå¤§å›¾ä¸­ï¼‰

    Args:
        metrics_tracker: æŒ‡æ ‡è¿½è¸ªå™¨
        output_path: ä¿å­˜è·¯å¾„
    """
    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

    # 1. è®­ç»ƒæŸå¤±
    ax1 = fig.add_subplot(gs[0, :2])
    if metrics_tracker.history.get('train_loss'):
        ax1.plot(metrics_tracker.history['step'], metrics_tracker.history['train_loss'],
                label='Training Loss', linewidth=2)
        if metrics_tracker.history.get('val_loss'):
            val_steps = [s for s, v in zip(metrics_tracker.history['step'],
                                           metrics_tracker.history['val_loss']) if v is not None]
            val_losses = [v for v in metrics_tracker.history['val_loss'] if v is not None]
            if val_losses:
                ax1.plot(val_steps, val_losses, label='Validation Loss', linewidth=2)
        ax1.set_xlabel('Steps')
        ax1.set_ylabel('Loss')
        ax1.set_title('Loss Curves', fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

    # 2. å­¦ä¹ ç‡
    ax2 = fig.add_subplot(gs[0, 2])
    if metrics_tracker.history.get('learning_rate'):
        ax2.plot(metrics_tracker.history['step'], metrics_tracker.history['learning_rate'],
                color='coral', linewidth=2)
        ax2.set_xlabel('Steps')
        ax2.set_ylabel('Learning Rate')
        ax2.set_title('Learning Rate', fontweight='bold')
        ax2.grid(True, alpha=0.3)

    # 3. GRPO å¥–åŠ±
    if metrics_tracker.grpo_history['step']:
        ax3 = fig.add_subplot(gs[1, :])
        ax3.plot(metrics_tracker.grpo_history['step'],
                metrics_tracker.grpo_history['mean_reward'],
                label='Mean Reward', linewidth=2)
        ax3.fill_between(
            metrics_tracker.grpo_history['step'],
            metrics_tracker.grpo_history['min_reward'],
            metrics_tracker.grpo_history['max_reward'],
            alpha=0.2
        )
        ax3.set_xlabel('Steps')
        ax3.set_ylabel('Reward')
        ax3.set_title('GRPO Rewards', fontweight='bold')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

    # 4. æŸå¤±åˆ†å¸ƒï¼ˆå¦‚æœæœ‰å¤šä¸ª epochï¼‰
    ax4 = fig.add_subplot(gs[2, 0])
    if metrics_tracker.history.get('train_loss'):
        ax4.hist(metrics_tracker.history['train_loss'], bins=30, alpha=0.7, edgecolor='black')
        ax4.set_xlabel('Loss')
        ax4.set_ylabel('Frequency')
        ax4.set_title('Loss Distribution', fontweight='bold')
        ax4.grid(True, alpha=0.3, axis='y')

    # 5. æ¯ä¸ª Epoch çš„å¹³å‡æŸå¤±
    ax5 = fig.add_subplot(gs[2, 1])
    if metrics_tracker.history.get('epoch') and metrics_tracker.history.get('train_loss'):
        df = pd.DataFrame({
            'epoch': metrics_tracker.history['epoch'],
            'train_loss': metrics_tracker.history['train_loss']
        })
        epoch_loss = df.groupby('epoch')['train_loss'].mean()
        ax5.plot(epoch_loss.index, epoch_loss.values, marker='o', linewidth=2)
        ax5.set_xlabel('Epoch')
        ax5.set_ylabel('Average Loss')
        ax5.set_title('Loss per Epoch', fontweight='bold')
        ax5.grid(True, alpha=0.3)

    # æ·»åŠ æ€»æ ‡é¢˜
    fig.suptitle('Training Dashboard', fontsize=20, fontweight='bold', y=0.995)

    if output_path:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ Training dashboard saved to {output_path}")
    else:
        save_path = metrics_tracker.plots_dir / f"{metrics_tracker.experiment_name}_dashboard.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ Training dashboard saved to {save_path}")

    plt.close()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("Testing Visualization Tools...\n")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    tracker = MetricsTracker("./test_output", "test_experiment")

    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    for step in range(100):
        epoch = step // 20
        tracker.log_metrics(
            step=step,
            epoch=epoch,
            metrics={
                'train_loss': 2.0 * np.exp(-step/50) + 0.1,
                'val_loss': 2.1 * np.exp(-step/50) + 0.15 if step % 10 == 0 else None,
                'learning_rate': 2e-4 * (1 - step/100)
            }
        )

        if step > 50:  # æ¨¡æ‹Ÿ GRPO è®­ç»ƒ
            tracker.log_grpo_metrics(
                step=step,
                metrics={
                    'mean_reward': 0.5 + 0.3 * (step - 50) / 50,
                    'max_reward': 0.8 + 0.2 * (step - 50) / 50,
                    'min_reward': 0.2 + 0.1 * (step - 50) / 50,
                    'kl_divergence': 0.1 * np.exp(-(step-50)/25)
                }
            )

    # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
    tracker.plot_all()
    tracker.save_metrics()
    tracker.generate_summary_report()

    # åˆ›å»ºä»ªè¡¨æ¿
    create_training_dashboard(tracker)

    print("\nâœ“ Test completed! Check ./test_output/plots/")
